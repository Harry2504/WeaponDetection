{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "import time \n",
    "import urllib.request\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from utils import label_map_util\n",
    "from utils import visualization_utils as vis_util\n",
    "\n",
    "def load_image_into_numpy_array(image):\n",
    "  (im_width, im_height) = image.size\n",
    "  return np.array(image.getdata()).reshape(\n",
    "      (im_height, im_width, 3)).astype(np.uint8)\n",
    "\n",
    "\n",
    "# the argument temp is the path for the image like if the image is the folder in \n",
    "#validation then temp='validation/image2.jpg' \n",
    "def people_knives(temp):\n",
    "    MODEL_NAME = './outputs/faster_rcnn/faster_rcnn_inception_v2_coco_2018_01_28'\n",
    "    PATH_TO_CKPT = MODEL_NAME + '/frozen_inference_graph.pb'\n",
    "    PATH_TO_LABELS = os.path.join('data', 'mscoco_label_map.pbtxt')\n",
    "    NUM_CLASSES = 90\n",
    "    \n",
    "    detection_graph = tf.Graph()\n",
    "    with detection_graph.as_default():\n",
    "        od_graph_def = tf.compat.v1.GraphDef()\n",
    "        with tf.compat.v1.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
    "            serialized_graph = fid.read()\n",
    "            od_graph_def.ParseFromString(serialized_graph)\n",
    "            tf.import_graph_def(od_graph_def, name='')\n",
    "    \n",
    "    label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "    categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
    "    category_index = label_map_util.create_category_index(categories)\n",
    "            \n",
    "    TEST_IMAGE_PATHS = [ os.path.join(temp)]\n",
    "    # Size, in inches, of the output images.\n",
    "    IMAGE_SIZE = (12, 8)\n",
    "    with detection_graph.as_default():\n",
    "        with tf.compat.v1.Session(graph=detection_graph) as sess:\n",
    "            # Definite input and output Tensors for detection_graph\n",
    "            image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "            # Each box represents a part of the image where a particular object was detected.\n",
    "            detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "            # Each score represent how level of confidence for each of the objects.\n",
    "            # Score is shown on the result image, together with the class label.\n",
    "            detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "            detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "            num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "            i='0'\n",
    "            j=0\n",
    "            for image_path in TEST_IMAGE_PATHS:\n",
    "                #image = Image.open(temp)\n",
    "                response = requests.get(temp)\n",
    "                image= Image.open(BytesIO(response.content))\n",
    "                # the array based representation of the image will be used later in order to prepare the\n",
    "                # result image with boxes and labels on it.\n",
    "                image_np = load_image_into_numpy_array(image)\n",
    "                # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
    "                image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "                # Actual detection.\n",
    "                (boxes, scores, classes, num) = sess.run(\n",
    "                [detection_boxes, detection_scores, detection_classes, num_detections],\n",
    "                feed_dict={image_tensor: image_np_expanded})\n",
    "                # Visualization of the results of a detection.\n",
    "                p = vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "               image_np,\n",
    "               np.squeeze(boxes),\n",
    "               np.squeeze(classes).astype(np.int32),\n",
    "               np.squeeze(scores),\n",
    "               category_index,\n",
    "               use_normalized_coordinates=True,\n",
    "               line_thickness=1)\n",
    "                if(len(p)==0):\n",
    "                    return (\"\")\n",
    "                else:\n",
    "\n",
    "                    j=0\n",
    "                    person=0\n",
    "                    flag=0\n",
    "                    flag1=0\n",
    "                    flag2=0\n",
    "                    n=len(p)\n",
    "                    ans=\"\"\n",
    "                    temp1=\"\"\n",
    "                    while(j<n):\n",
    "                        temp1 = \"\"\n",
    "                        \n",
    "                        while(p[j]!=':'):\n",
    "                            temp1 = temp1 + p[j]\n",
    "                            j=j+1\n",
    "                                                \n",
    "                        if(temp1==\"person\"):\n",
    "                            if(p[j]==':'):\n",
    "                                j=j+2\n",
    "                                temp=0\n",
    "                                while(p[j]!='.' and p[j]!='%'):\n",
    "                                    temp = temp*10 + ord(p[j]) - 48\n",
    "                                    j=j+1\n",
    "                                if(temp>95):\n",
    "                                    person = person + 1\n",
    "                        \n",
    "                        elif(temp1==\"knife\"):\n",
    "                            if(p[j]==':'):\n",
    "                                j=j+2\n",
    "                                temp=0\n",
    "                                while(p[j]!='.' and p[j]!='%'):\n",
    "                                    temp = temp*10 + ord(p[j]) - 48\n",
    "                                    j=j+1\n",
    "                                if(temp>=59 and flag==0):\n",
    "                                    ans+=temp1+\" ,\"\n",
    "                                    flag=1\n",
    "                                    \n",
    "                        elif(temp1==\"baseball bat\"):\n",
    "                            if(p[j]==':'):\n",
    "                                j=j+2\n",
    "                                temp=0\n",
    "                                while(p[j]!='.' and p[j]!='%' ):\n",
    "                                    temp = temp*10 + ord(p[j]) - 48\n",
    "                                    j=j+1\n",
    "                                if(temp>=59 and flag1==0):\n",
    "                                    ans+=temp1+\" ,\"\n",
    "                                    flag1=1\n",
    "                                    \n",
    "                        elif(temp1==\"scissors\"):\n",
    "                            if(p[j]==':'):\n",
    "                                j=j+2\n",
    "                                temp=0\n",
    "                                while(p[j]!='.' and p[j]!='%'):\n",
    "                                    temp = temp*10 + ord(p[j]) - 48\n",
    "                                    j=j+1\n",
    "                                if(temp>=59 and flag2==0):\n",
    "                                    ans+=temp1+\" ,\"\n",
    "                                    flag2=1\n",
    "                                    \n",
    "                        while(p[j]!='%'):\n",
    "                            j=j+1\n",
    "                        j=j+1\n",
    "                        if(p[j]=='$'):\n",
    "                            break\n",
    "                    \n",
    "                    if(person>0):\n",
    "                        if(person==1 and flag == 0 and flag1 == 0 and flag2 == 0):\n",
    "                            ans = ans + \"1 person\"\n",
    "                        elif(person==1):\n",
    "                            ans = ans + \"and 1 person\"\n",
    "                        elif(person>1 and flag == 0 and flag1 == 0 and flag2 == 0):\n",
    "                            ans = ans + str(person) + \" people\"\n",
    "                        else:\n",
    "                            ans = ans + \"and \" + str(person) + \" people\"\n",
    "            return ans\n",
    "\n",
    "\n",
    "\n",
    "# the argument temp is the path for the image like if the image is the folder in \n",
    "#validation then temp='validation/image2.jpg' \n",
    "def gun_detection(temp):\n",
    "    MODEL_NAME = './outputs/faster_rcnn/faster_rcnn_inception_v2_graph_output'\n",
    "    PATH_TO_CKPT = MODEL_NAME + '/frozen_inference_graph.pb'\n",
    "    PATH_TO_LABELS = os.path.join('./outputs/faster_rcnn/training', 'object-detection.pbtxt')\n",
    "    NUM_CLASSES = 1\n",
    "    \n",
    "    detection_graph = tf.Graph()\n",
    "    with detection_graph.as_default():\n",
    "        od_graph_def = tf.compat.v1.GraphDef()\n",
    "        with tf.compat.v1.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
    "            serialized_graph = fid.read()\n",
    "            od_graph_def.ParseFromString(serialized_graph)\n",
    "            tf.import_graph_def(od_graph_def, name='')\n",
    "    \n",
    "    label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "    categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
    "    category_index = label_map_util.create_category_index(categories)\n",
    "            \n",
    "    TEST_IMAGE_PATHS = [ os.path.join(temp)]\n",
    "    # Size, in inches, of the output images.\n",
    "    IMAGE_SIZE = (12, 8)\n",
    "    with detection_graph.as_default():\n",
    "        with tf.compat.v1.Session(graph=detection_graph) as sess:\n",
    "            # Definite input and output Tensors for detection_graph\n",
    "            image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "            # Each box represents a part of the image where a particular object was detected.\n",
    "            detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "            # Each score represent how level of confidence for each of the objects.\n",
    "            # Score is shown on the result image, together with the class label.\n",
    "            detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "            detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "            num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "            i='0'\n",
    "            j=0\n",
    "            for image_path in TEST_IMAGE_PATHS:\n",
    "                response = requests.get(temp)\n",
    "                image= Image.open(BytesIO(response.content))\n",
    "                #image = Image.open(temp)\n",
    "                # the array based representation of the image will be used later in order to prepare the\n",
    "                # result image with boxes and labels on it.\n",
    "                image_np = load_image_into_numpy_array(image)\n",
    "                # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
    "                image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "                # Actual detection.\n",
    "                (boxes, scores, classes, num) = sess.run(\n",
    "                [detection_boxes, detection_scores, detection_classes, num_detections],\n",
    "                feed_dict={image_tensor: image_np_expanded})\n",
    "                # Visualization of the results of a detection.\n",
    "                l = vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "               image_np,\n",
    "               np.squeeze(boxes),\n",
    "               np.squeeze(classes).astype(np.int32),\n",
    "               np.squeeze(scores),\n",
    "               category_index,\n",
    "               use_normalized_coordinates=True,\n",
    "               line_thickness=1)\n",
    "\n",
    "                ans = \"\"\n",
    "                if(len(l)!=0):\n",
    "                    j=0\n",
    "                    flag=0\n",
    "                    n=len(l)\n",
    "                    for j in range(n):\n",
    "                        if(l[j]==':'):\n",
    "                            j=j+2\n",
    "                            temp2=0\n",
    "                            while (l[j]!='.' and l[j]!='%'):\n",
    "                                temp2 = (temp2)*10 + ord(l[j]) - 48\n",
    "                                j=j+1\n",
    "                            if(temp2>70):\n",
    "                                flag=1\n",
    "                                break\n",
    "                        j=j+1        \n",
    "                    if(flag==1):\n",
    "                        ans = \"Gun\"\n",
    "                    else:\n",
    "                        ans = \"\"\n",
    "                h = people_knives(temp)\n",
    "                if(len(h+ans)==0):\n",
    "                    print(\"Nothing detected in the image.\")\n",
    "                else:\n",
    "                    if(len(ans)==0):\n",
    "                        ans = ans + h + \" detected in the image.\" \n",
    "                    elif(len(h)==0):\n",
    "                        ans = ans + \" detected in the image.\"\n",
    "                    else:\n",
    "                        ans = ans + \" ,\" + h + \" detected in the image.\"      \n",
    "            print(ans)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 person detected in the image.\n"
     ]
    }
   ],
   "source": [
    "gun_detection(\"https://engineering.unl.edu/images/staff/Kayla_Person-small.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
